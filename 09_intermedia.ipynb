{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "D5fMYLkWoUlM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RandomizedSearchCV, ParameterGrid\n",
        "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, make_scorer\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, roc_auc_score\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "\n",
        "from IPython.display import Image, display\n",
        "url = \"https://i.imgur.com/VVzDmjr.jpeg\"\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/aprendizaje-automatico-dc-uba-ar/material/main/tp/01_aprendizaje_supervisado/datos/data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bCAhm_npbMh"
      },
      "source": [
        "# Ejercicio 1 — Separación de datos\n",
        "\n",
        "> *Evaluar y justificar cómo separarán sus datos para desarrollo y para evaluación. No usar `train_test_split` de sklearn.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Yy2-VnraDs"
      },
      "source": [
        "Antes de separar los 500 datos en conjuntos de desarrollo y test, analizamos la variable `target` para contar cuántas instancias son positivas y cuántas negativas. La idea es darnos cuenta si las clases estan balanceadas o no . En el segundo caso , deberiamos hacer una división estratificada.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "eARoHw6Br9Rp",
        "outputId": "49505a39-aa96-474e-cde3-4cdbcb3d3cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "target\n",
              "0    353\n",
              "1    147\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['target'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjXk6xUMsMxo"
      },
      "source": [
        "El data set está muy desbalanceado, hay muchas mas instancias con mal pronostico (target 0) y solo un 29 % de los datos tienen buen pronostico (target 1). Así que para separar nuestros datos no lo haremos al azar. La separación sera estratificada para que la proporcion de la clase minoritaria ( buen pronostico) se preserve en ambos conjuntos. Utilizaremos 80 % de los datos para train y 20 % para control.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhK6YEBS64dg"
      },
      "source": [
        "Haciendo la partición en 80-20, tenemos 400 instancias en el conjunto de desarrollo y 100 en el de control. Para garantizar la estratificación, seleccionamos aproximadamente el 20% de los casos positivos y el 20% de los negativos para formar el conjunto de control. De esta manera , ambos conjuntos mantienen la proporción original de clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3aejzrKvTbu"
      },
      "source": [
        "Inicialmente entonces creamos dos data sets distintos. Uno destinado para el desarrolo y otro para la evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOZg1sYjs6ix",
        "outputId": "bf4c09da-6894-4b68-820c-ba35ab16c39e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Desarrollo: 400 instancias\n",
            "Control: 100 instancias\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# separamos positivos (buen pronostico) y negativos (mal pronsotico)\n",
        "positivos = df[df['target'] == True]\n",
        "negativos = df[df['target'] == False]\n",
        "\n",
        "# seleccionamos al azar el 20% para control\n",
        "control_positivos = positivos.sample(frac=0.2, random_state=22)\n",
        "control_negativos = negativos.sample(frac=0.2, random_state=22)\n",
        "\n",
        "# concatenamos el set de control\n",
        "NO_TOCAR_set = pd.concat([control_positivos, control_negativos])   # NO TOCAR\n",
        "\n",
        "# El resto de los datos queda para desarrollo\n",
        "desarrollo_set = df.drop(NO_TOCAR_set.index)\n",
        "\n",
        "print(f\"Desarrollo: {len(desarrollo_set)} instancias\")\n",
        "print(f\"Control: {len(NO_TOCAR_set)} instancias\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHIPrs1_wLHG"
      },
      "source": [
        "# Ejercicio 2 — Entrenamiento\n",
        "\n",
        "> *Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. Estimar la performance del modelo utilizando K-fold cross validation con K=5, con las métricas Accuracy, Area Under the Precision-Recall Curve (AUPRC), y Area Under the Receiver Operating Characteristic Curve (AUCROC).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1eMlXDAuzVk"
      },
      "source": [
        "Para hacer CV con 5 folds, vamos a hacer una division estratificada. Como ya dijimos antes, tenemos muy pocos positivos y muchos negativos, las clases estan muy desbalanceadas, por ende, si hicieramos la division de Kfold-CV al azar, podríamos obtener un modelo entrenado con una sola clase y métricas engañosas ... no es la idea.\n",
        "Asi que vamos a usar K-fold-CV estratificado para mantener la proporcion de clases en cada fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BCmauosmz23z"
      },
      "outputs": [],
      "source": [
        "# hacemos 5 folds estratificados para que haya las mismas proprciones de clases minoritarias y mayoritarias en todos los folds.\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 22)\n",
        "\n",
        "# separamos de nuestro data set la columna \"target\"\n",
        "desarrollo_set = desarrollo_set.reset_index(drop=True)\n",
        "x_desarrollo = desarrollo_set.drop('target', axis=1)\n",
        "y_desarrollo = desarrollo_set['target']\n",
        "\n",
        "\n",
        "# inicializamos nuestras listas para guadar las metricas\n",
        "vector_accuracy_train= []       # accuracy en training en cada fold\n",
        "vector_accuracy_validacion= []  # lo mismo en validacion\n",
        "\n",
        "vector_auprc_train  = []        # AUPRC en training en cada fold\n",
        "vector_auprc_validacion = []    # lo mismo pero en validacion\n",
        "\n",
        "vector_auroc_train = []         # AUC-ROC en training en cada fold\n",
        "vector_auroc_validacion=[]      # lo mismo pero en validacion\n",
        "\n",
        "\n",
        "# creamos un array para guardar las predicciones\n",
        "y_pred = np.empty(y_desarrollo.shape)\n",
        "y_pred.fill(np.nan)\n",
        "\n",
        "# lo mismo pero para guardar la probabilidad predicha de pertenecer a la clase positiva\n",
        "# esto lo vamos a usar para calcular AUC-ROC y AUPRC\n",
        "y_pred_prob = np.empty(y_desarrollo.shape)\n",
        "y_pred_prob.fill(np.nan)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z4bmfgMMyclj"
      },
      "outputs": [],
      "source": [
        "# generamos para cada fold una predicción\n",
        "for train_index, test_index in folds.split(x_desarrollo,y_desarrollo):\n",
        "\n",
        "        # sacamos el fold que no usamos para entrenar\n",
        "        kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "        kf_y_train, kf_y_test = y_desarrollo.iloc[train_index], y_desarrollo.iloc[test_index]\n",
        "\n",
        "        # arbol de altura 3 con los datos de train\n",
        "        arbol = DecisionTreeClassifier(max_depth=3)\n",
        "        arbol.fit(kf_X_train, kf_y_train)\n",
        "        y_pred_prob[test_index] = arbol.predict_proba(kf_X_test)[:, 1] # la prob pred de clase positiva para val de ese fold\n",
        "\n",
        "        # hacemos las predicciones\n",
        "        predictions = arbol.predict(kf_X_test)\n",
        "        y_pred[test_index] = predictions\n",
        "\n",
        "        # accuracy\n",
        "        vector_accuracy_validacion.append(accuracy_score(kf_y_test, predictions))\n",
        "        vector_accuracy_train.append(accuracy_score(kf_y_train, arbol.predict(kf_X_train)))\n",
        "\n",
        "        # AUPRC\n",
        "        auprc = average_precision_score(kf_y_test, arbol.predict_proba(kf_X_test)[:, 1])\n",
        "        vector_auprc_validacion.append(auprc)\n",
        "        vector_auprc_train.append(average_precision_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "\n",
        "        # AUROC\n",
        "        auc_roc = roc_auc_score(kf_y_test, arbol.predict_proba(kf_X_test)[:, 1])\n",
        "        vector_auroc_validacion.append(auc_roc)\n",
        "        vector_auroc_train.append(roc_auc_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJqBomLR1JNm",
        "outputId": "3e3fe9d3-1167-4af2-d4e0-5582a0bba8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio de accuracys por fold: 0.725\n",
            "Accuracy global: 0.725\n",
            "\n",
            "Promedio de AUPRC por fold: 0.4841\n",
            "AUPRC global: 0.4931\n",
            "\n",
            "Promedio de AUROC por fold: 0.7067\n",
            "AUROC global: 0.712\n"
          ]
        }
      ],
      "source": [
        "# accuracy\n",
        "print(\"Promedio de accuracys por fold:\", round(np.mean(vector_accuracy_validacion), 4))\n",
        "print(\"Accuracy global:\", round(accuracy_score(y_desarrollo, y_pred), 4))\n",
        "print()\n",
        "\n",
        "# AUPRC\n",
        "print(\"Promedio de AUPRC por fold:\", round(np.mean(vector_auprc_validacion), 4))\n",
        "print(\"AUPRC global:\", round(average_precision_score(y_desarrollo, y_pred_prob), 4))\n",
        "print()\n",
        "\n",
        "# AUROC\n",
        "print(\"Promedio de AUROC por fold:\", round(np.mean(vector_auroc_validacion), 4))\n",
        "print(\"AUROC global:\", round(roc_auc_score(y_desarrollo, y_pred_prob), 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "1WfEDUus3Nw2",
        "outputId": "f10571c8-4f81-4d12-d00d-3b400e22f951"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "| Métrica  | Promedio Fold | Global |\n",
              "|:--------:|:-------------:|:------:|\n",
              "| Accuracy |     0.7250    | 0.7250 |\n",
              "| AUPRC    |     0.4841    | 0.4931 |\n",
              "| AUROC    |     0.7067    | 0.7120 |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Ingresamos los valores a mano\n",
        "# No debería haber cambios con respecto a la posterior tabla, ya que fijamos una semilla\n",
        "\n",
        "tabla_md = \"\"\"\n",
        "| Métrica  | Promedio Fold | Global |\n",
        "|:--------:|:-------------:|:------:|\n",
        "| Accuracy |     0.7250    | 0.7250 |\n",
        "| AUPRC    |     0.4841    | 0.4931 |\n",
        "| AUROC    |     0.7067    | 0.7120 |\n",
        "\"\"\"\n",
        "\n",
        "display(Markdown(tabla_md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPVktS5r3jnd"
      },
      "source": [
        "A pesar de que obtuvimos un accuracy del 70%, este valor no es significativo debido al fuerte desbalance de clases del dataset. De por si un clasificador dummy que predice siempre la clase negativa (mal pronóstico) alcanzaría dicha predicción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci_-7SNH4Cri"
      },
      "source": [
        "Si miramos los resultados del AUPRC, considerando que nosotras tenemos clase positiva minoritaria, un modelo trivial tendria aproximadamente un AUPRC ≈ 0.29. El nuestro nos dio mejor que eso, asi que en este caso al menos superamos al azar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLIqClcD4ZM6"
      },
      "source": [
        "Un modelo totalmente random tendria un AUROC de 0.5. El nuestro es un poco mejor, pero igualmente no nos parece tan bueno aún.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvjUJegA2oPF"
      },
      "source": [
        "En lo siguiente, completamos la tabla que se nos pide en el TP con los resultados obtenidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "LC_TPoC15T62",
        "outputId": "26c0a21c-d1b0-4e00-d582-cdff987d2fb7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Permutación</th>\n",
              "      <th>Accuracy (training)</th>\n",
              "      <th>Accuracy (validación)</th>\n",
              "      <th>AUPRC (training)</th>\n",
              "      <th>AUPRC (validación)</th>\n",
              "      <th>AUC ROC (training)</th>\n",
              "      <th>AUC ROC (validación)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.529</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.863</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.822</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.729</td>\n",
              "      <td>0.413</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.721</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.827</td>\n",
              "      <td>0.483</td>\n",
              "      <td>0.902</td>\n",
              "      <td>0.716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Promedio</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Global</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.725</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.493</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# creamos la tabla que se nos pide con los resultados obtenidos\n",
        "\n",
        "tabla_resultados = pd.DataFrame({\n",
        "    \"Permutación\": list(range(1, len(vector_accuracy_validacion)+1)),\n",
        "    \"Accuracy (training)\": [round(x,3) for x in vector_accuracy_train],\n",
        "    \"Accuracy (validación)\": [round(x,3) for x in vector_accuracy_validacion],\n",
        "    \"AUPRC (training)\": [round(x,3) for x in vector_auprc_train],\n",
        "    \"AUPRC (validación)\": [round(x,3) for x in vector_auprc_validacion],\n",
        "    \"AUC ROC (training)\": [round(x,3) for x in vector_auroc_train],\n",
        "    \"AUC ROC (validación)\": [round(x,3) for x in vector_auroc_validacion]\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "promedios = {\n",
        "    \"Permutación\": \"Promedio\",\n",
        "    \"Accuracy (training)\": round(np.mean(vector_accuracy_train), 3),\n",
        "    \"Accuracy (validación)\": round(np.mean(vector_accuracy_validacion), 3),\n",
        "    \"AUPRC (training)\": round(np.mean(vector_auprc_train), 3),\n",
        "    \"AUPRC (validación)\": round(np.mean(vector_auprc_validacion), 3),\n",
        "    \"AUC ROC (training)\": round(np.mean(vector_auroc_train), 3),\n",
        "    \"AUC ROC (validación)\": round(np.mean(vector_auroc_validacion), 3)\n",
        "}\n",
        "\n",
        "\n",
        "globales = {\n",
        "    \"Permutación\": \"Global\",\n",
        "    \"Accuracy (training)\": \"(NO)\",\n",
        "    \"Accuracy (validación)\": round(accuracy_score(y_desarrollo, y_pred), 3),\n",
        "    \"AUPRC (training)\": \"(NO)\",\n",
        "    \"AUPRC (validación)\": round(average_precision_score(y_desarrollo, y_pred_prob), 3),\n",
        "    \"AUC ROC (training)\": \"(NO)\",\n",
        "    \"AUC ROC (validación)\": round(roc_auc_score(y_desarrollo, y_pred_prob), 3)\n",
        "}\n",
        "\n",
        "tabla_resultados = pd.concat([\n",
        "    tabla_resultados,\n",
        "    pd.DataFrame([promedios]),\n",
        "    pd.DataFrame([globales])\n",
        "], ignore_index=True)\n",
        "\n",
        "display(HTML(tabla_resultados.to_html(index=False, justify='center')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFQQZkDlhIH-"
      },
      "source": [
        "Dado que la clase positiva es la clase minoritaria, tiene sentido que AUPRC sea baja. La AUPRC (Area Under Precision-Recall Curve) es muy sensible al desbalance de clases.\n",
        "\n",
        "El AUPRC grafica la relacion entre el precision y el recall. Al tener pocos positivos, el modelo, en su búsqueda por encontrar más TP (aumentar el Recall), tiende a generar muchos FP. Este aumento de FPs impacta directamente en la fórmula de la Precision (TP/TP+FP), haciendo que baje drásticamentre, y por lo tanto, que la curva y su área sean menores.\n",
        "\n",
        "En cambio, el AUCROC compara el Recall(TPR) con la FPR. La FPR se calcula como FP/FP+TN y como tenemos muchos TN (porque hay más negativos que positivos en la muestra), la tasa se mantiene baja aunque el número de FP sea alto. Por esta razón es que el desbalance no se ve reflejado en esta métrica tanto como en la otra.\n",
        "\n",
        "Adicionalmente, es lógico que los resultados en los folds de entrenamiento sean muy superiores a los de validación. Esto se debe al overfitting, ya que el modelo \"memoriza\" (hasta cierto punto) los datos con los que entrena."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbEj0_z6tP_Z"
      },
      "source": [
        "Tiene sentido que el promedio de igual al global en este caso particular porque los folds tienen todos basicamente el mismo tamaño. Si los folds tuvieran todos tamaños lo suficientemente distintos, entonces el fold con más instancias tendría más “peso” en el cálculo global, y entonces en ese caso el promedio podria no coincidir con el  global."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "m4jyLM_viVkb",
        "outputId": "d2a55c9e-1923-40c4-cd84-bf4acc75e9f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Permutación</th>\n",
              "      <th>Accuracy (training)</th>\n",
              "      <th>Accuracy (validación)</th>\n",
              "      <th>AUPRC (training)</th>\n",
              "      <th>AUPRC (validación)</th>\n",
              "      <th>AUC ROC (training)</th>\n",
              "      <th>AUC ROC (validación)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.866</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.929</td>\n",
              "      <td>0.814</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.863</td>\n",
              "      <td>0.787</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.881</td>\n",
              "      <td>0.833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.822</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.904</td>\n",
              "      <td>0.786</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.761</td>\n",
              "      <td>0.837</td>\n",
              "      <td>0.599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.932</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.902</td>\n",
              "      <td>0.716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Promedio</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.725</td>\n",
              "      <td>0.914</td>\n",
              "      <td>0.819</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Global</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.725</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.822</td>\n",
              "      <td>(NO)</td>\n",
              "      <td>0.712</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cosas extra que quisimos probar por curiosidad:\n",
        "\n",
        "#  Dado que la clase mayoritaria son los negativos, probamos invertir las etiquetas y ver que sucede\n",
        "#  Invirtiendo las etiquetas de las predicciones observamos que las metricas dan numeros mas altos\n",
        "\n",
        "# datos\n",
        "desarrollo_set = desarrollo_set.reset_index(drop=True)\n",
        "x_desarrollo = desarrollo_set.drop('target', axis=1)\n",
        "y_desarrollo = desarrollo_set['target']\n",
        "\n",
        "# inversion de clases positiva a negativa y negativa a positiva\n",
        "y_desarrollo_invertida = 1 - y_desarrollo\n",
        "\n",
        "# hacemos los k folds\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=22)\n",
        "\n",
        "# vectores de metricas\n",
        "vector_accuracy_train = []\n",
        "vector_accuracy_validacion = []\n",
        "vector_auprc_train = []\n",
        "vector_auprc_validacion = []\n",
        "vector_auroc_train = []\n",
        "vector_auroc_validacion = []\n",
        "\n",
        "# prediciones globales\n",
        "y_pred = np.empty(y_desarrollo.shape)\n",
        "y_pred.fill(np.nan)\n",
        "y_pred_prob = np.empty(y_desarrollo.shape)\n",
        "y_pred_prob.fill(np.nan)\n",
        "\n",
        "# empezamos el train\n",
        "for train_index, test_index in folds.split(x_desarrollo, y_desarrollo_invertida):\n",
        "    kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "    kf_y_train, kf_y_test = y_desarrollo_invertida.iloc[train_index], y_desarrollo_invertida.iloc[test_index]\n",
        "\n",
        "    arbol = DecisionTreeClassifier(max_depth=3)\n",
        "    arbol.fit(kf_X_train, kf_y_train)\n",
        "\n",
        "    y_pred_fold = arbol.predict(kf_X_test)\n",
        "    y_pred_prob_fold = arbol.predict_proba(kf_X_test)[:, 1]\n",
        "\n",
        "    y_pred[test_index] = y_pred_fold\n",
        "    y_pred_prob[test_index] = y_pred_prob_fold\n",
        "\n",
        "    vector_accuracy_train.append(accuracy_score(kf_y_train, arbol.predict(kf_X_train)))\n",
        "    vector_accuracy_validacion.append(accuracy_score(kf_y_test, y_pred_fold))\n",
        "    vector_auprc_train.append(average_precision_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "    vector_auprc_validacion.append(average_precision_score(kf_y_test, y_pred_prob_fold))\n",
        "    vector_auroc_train.append(roc_auc_score(kf_y_train, arbol.predict_proba(kf_X_train)[:, 1]))\n",
        "    vector_auroc_validacion.append(roc_auc_score(kf_y_test, y_pred_prob_fold))\n",
        "\n",
        "# calculamos metricas globales\n",
        "accuracy_global = accuracy_score(y_desarrollo_invertida, y_pred)\n",
        "auprc_global = average_precision_score(y_desarrollo_invertida, y_pred_prob)\n",
        "auroc_global = roc_auc_score(y_desarrollo_invertida, y_pred_prob)\n",
        "\n",
        "# hagamos una tabla para ver los resultados :\n",
        "tabla_resultados = pd.DataFrame({\n",
        "    \"Permutación\": list(range(1, 6)),\n",
        "    \"Accuracy (training)\": [round(x, 3) for x in vector_accuracy_train],\n",
        "    \"Accuracy (validación)\": [round(x, 3) for x in vector_accuracy_validacion],\n",
        "    \"AUPRC (training)\": [round(x, 3) for x in vector_auprc_train],\n",
        "    \"AUPRC (validación)\": [round(x, 3) for x in vector_auprc_validacion],\n",
        "    \"AUC ROC (training)\": [round(x, 3) for x in vector_auroc_train],\n",
        "    \"AUC ROC (validación)\": [round(x, 3) for x in vector_auroc_validacion]\n",
        "})\n",
        "\n",
        "\n",
        "promedios = {\n",
        "    \"Permutación\": \"Promedio\",\n",
        "    \"Accuracy (training)\": round(np.mean(vector_accuracy_train), 3),\n",
        "    \"Accuracy (validación)\": round(np.mean(vector_accuracy_validacion), 3),\n",
        "    \"AUPRC (training)\": round(np.mean(vector_auprc_train), 3),\n",
        "    \"AUPRC (validación)\": round(np.mean(vector_auprc_validacion), 3),\n",
        "    \"AUC ROC (training)\": round(np.mean(vector_auroc_train), 3),\n",
        "    \"AUC ROC (validación)\": round(np.mean(vector_auroc_validacion), 3)\n",
        "}\n",
        "\n",
        "globales = {\n",
        "    \"Permutación\": \"Global\",\n",
        "    \"Accuracy (training)\": \"(NO)\",\n",
        "    \"Accuracy (validación)\": round(accuracy_global, 3),\n",
        "    \"AUPRC (training)\": \"(NO)\",\n",
        "    \"AUPRC (validación)\": round(auprc_global, 3),\n",
        "    \"AUC ROC (training)\": \"(NO)\",\n",
        "    \"AUC ROC (validación)\": round(auroc_global, 3)\n",
        "}\n",
        "\n",
        "tabla_resultados = pd.concat([\n",
        "    tabla_resultados,\n",
        "    pd.DataFrame([promedios]),\n",
        "    pd.DataFrame([globales])\n",
        "], ignore_index=True)\n",
        "\n",
        "display(HTML(tabla_resultados.to_html(index=False, justify='center')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcLphbYoWjCF"
      },
      "source": [
        "Algunas conclusiones : el accuracy y el AUCROC no cambian mucho , tiene sentido ya que no dependen de a que clases tomamos como positivas o negativas. Por otro lado el AUPRC cambia bastante, ya que dependen de que clase tomamos como positiva. Lo notamos haciendo el experimento con las clases invertidas. Esto no dice que la metrica AUPRC depende de la elección de la clase positiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS1y77haAA9C"
      },
      "source": [
        "> *Explorar las siguientes combinaciones de parámetros para árboles de decisión utilizando `ParameterGrid` de scikit learn. No está permitido utilizar `GridSearchCV` en este ejercicio.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-2rSnCWDAGrT",
        "outputId": "2d38e06f-3a10-4997-f432-36874d5eea1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Altura máxima</th>\n",
              "      <th>Criterio de corte</th>\n",
              "      <th>Accuracy (train)</th>\n",
              "      <th>Accuracy (val)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Gini</td>\n",
              "      <td>0.856</td>\n",
              "      <td>0.725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>Gini</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Infinito</td>\n",
              "      <td>Gini</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Entropía</td>\n",
              "      <td>0.840</td>\n",
              "      <td>0.710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>Entropía</td>\n",
              "      <td>0.948</td>\n",
              "      <td>0.692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Infinito</td>\n",
              "      <td>Entropía</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Probamos disitnos parametros para nuestro arbol de decision\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state = 22)\n",
        "\n",
        "# Definimos el grid de parámetros que antes recorríamos manualmente\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, None],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Usamos ParameterGrid\n",
        "grid = ParameterGrid(param_grid)\n",
        "\n",
        "accuracy_validacion = {}\n",
        "accuracy_train = {}\n",
        "\n",
        "# Recorremos cada combinación de parámetros del grid\n",
        "for params in grid:\n",
        "    a = params['max_depth']\n",
        "    c = params['criterion']\n",
        "\n",
        "    vector_accuracy_validacion= []  # aca vamos a guardar los resultados de acurracy para cada fold de la validacion\n",
        "    vector_accuracy_train= []       # y del training\n",
        "\n",
        "    # generamos para cada fold una predicción\n",
        "    for train_index, test_index in folds.split(x_desarrollo,y_desarrollo):\n",
        "\n",
        "        #saco el fold que no uso para entrenar\n",
        "        kf_X_train, kf_X_test = x_desarrollo.iloc[train_index], x_desarrollo.iloc[test_index]\n",
        "        kf_y_train, kf_y_test = y_desarrollo.iloc[train_index], y_desarrollo.iloc[test_index]\n",
        "\n",
        "        # arbol fit con los datos de train\n",
        "        arbol = DecisionTreeClassifier(max_depth=a, criterion=c)\n",
        "        arbol.fit(kf_X_train, kf_y_train)\n",
        "\n",
        "        y_pred_val = arbol.predict(kf_X_test)\n",
        "        acc_val = accuracy_score(kf_y_test, y_pred_val)\n",
        "        vector_accuracy_validacion.append(acc_val)\n",
        "\n",
        "        y_pred_train = arbol.predict(kf_X_train)\n",
        "        acc_train = accuracy_score(kf_y_train, y_pred_train)\n",
        "        vector_accuracy_train.append(acc_train)\n",
        "\n",
        "    # Guardamos el promedio de accuracy de los folds\n",
        "    accuracy_validacion[(a, c)] = np.mean(vector_accuracy_validacion)\n",
        "    accuracy_train[(a, c)] = np.mean(vector_accuracy_train)\n",
        "\n",
        "# hacemos la tabla de resultados :\n",
        "# Lista para guardar filas de la tabla\n",
        "tabla_resultados = []\n",
        "\n",
        "# Recorremos las claves del diccionario (pares de (altura, criterio))\n",
        "for clave in accuracy_train.keys():\n",
        "    altura, criterio = clave\n",
        "    acc_train = accuracy_train[clave]\n",
        "    acc_val = accuracy_validacion[clave]\n",
        "\n",
        "    # Convertimos None en \"Infinito\" para mostrar en la tabla\n",
        "    altura_str = 'Infinito' if altura is None else altura\n",
        "    criterio_str = 'Gini' if criterio == 'gini' else 'Entropía'\n",
        "\n",
        "    # Agregamos una fila a la tabla\n",
        "    tabla_resultados.append({\n",
        "        'Altura máxima': altura_str,\n",
        "        'Criterio de corte': criterio_str,\n",
        "        'Accuracy (train)': round(acc_train, 3),\n",
        "        'Accuracy (val)': round(acc_val, 3)\n",
        "    })\n",
        "\n",
        "df_resultados = pd.DataFrame(tabla_resultados)\n",
        "display(HTML(df_resultados.to_html(index=False, justify='center')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFuFzoZpFSJe"
      },
      "source": [
        "Claramente a medida de que aumentamos la altura maxima del arbol, vemos que la accuracy en los datos de train tiende a 100%, lo que tiene sentido, ya que clasifica bien todos estos datos (los memoriza). Es decir, que el modelo a medida que la altura tiende a inf overfitea. A su vez, para los datos de validacion, el accuracy resulta peor. El modelo memoriza los datos de entrenamiendo y luego tiene un rendimiento peor en los datos de validacion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08QWSDpuGclp"
      },
      "source": [
        "Por curiosidad propia, estuvimos probando con otros valores y llegamos a la conclusion que la mejor altura es 2, ya que no solo, comparado a la performarnce en el test con otra alturas, es mejor, sino que tambien la diferencia con los datos de training es menor, osea que esta generalizando bastante bien, y no memoriza solo los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "nAoleS0feb2-",
        "outputId": "2d977291-2180-4952-bb63-d344d6443ccd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Altura máxima</th>\n",
              "      <th>Criterio de corte</th>\n",
              "      <th>Accuracy (train)</th>\n",
              "      <th>Accuracy (val)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Gini</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Entropía</td>\n",
              "      <td>0.779</td>\n",
              "      <td>0.735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# mostramos la tabla que nos salio\n",
        "tabla = [\n",
        "    {'Altura máxima': 2, 'Criterio de corte': 'Gini', 'Accuracy (train)': 0.784, 'Accuracy (val)': 0.722},\n",
        "    {'Altura máxima': 2, 'Criterio de corte': 'Entropía', 'Accuracy (train)': 0.779, 'Accuracy (val)': 0.735}\n",
        "]\n",
        "\n",
        "df_tabla = pd.DataFrame(tabla)\n",
        "\n",
        "display(HTML(df_tabla.to_html(index=False, justify='center')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaVJn8Bbj5g0"
      },
      "source": [
        "# Ejercicio 3\n",
        "\n",
        "*Importante: de acá en más sólamente utilizaremos el score promedio cuando hagamos K-fold cross-validation.*\n",
        "\n",
        "<u>Para el árbol de decisión elegimos jugar con los siguientes hiperparámetros:</u>\n",
        "\n",
        "* Max_depth (para regular el tamaño del árbol)\n",
        "* class_weight (para tratar el desbalanceo de clases que tenemos)\n",
        "* criterion (puede ser Gini o Entropia)\n",
        "* min_samples_split (para definir cuántos hijos vamos a tener por rama como máximo)\n",
        "\n",
        "<u>Por otro lado, para KNN elegimos:</u>\n",
        "\n",
        "* La cantidad de vecinos (k)\n",
        "* weights (darle más peso a los que están más cercanos y menos a los más alejados)\n",
        "* metrics (el tipo de distancia que usamos, tenemos 3 distintas)\n",
        "\n",
        "<u>Finalmente, para SVM:</u>\n",
        "\n",
        "* C (penalización por clasificación equivocada)\n",
        "* kernel (tenemos el radial, lineal, sigmoide, polinomico)\n",
        "* Gamma\n",
        "* class_weight (al ser desbalanceada nos conviene jugar con esto)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9eIiPtZv0g4"
      },
      "source": [
        "# Árboles de Decisión\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "UehCQwm1Skcs",
        "outputId": "616aecee-2ce7-425d-9254-767d08b22ee5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>param_criterion</th>\n",
              "      <th>param_class_weight</th>\n",
              "      <th>mean_test_roc_auc</th>\n",
              "      <th>mean_train_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>250</td>\n",
              "      <td>entropy</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6840</td>\n",
              "      <td>0.7055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>None</td>\n",
              "      <td>250</td>\n",
              "      <td>entropy</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6840</td>\n",
              "      <td>0.7055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4</td>\n",
              "      <td>250</td>\n",
              "      <td>gini</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6840</td>\n",
              "      <td>0.7055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>None</td>\n",
              "      <td>250</td>\n",
              "      <td>gini</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6840</td>\n",
              "      <td>0.7055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>entropy</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6676</td>\n",
              "      <td>0.7518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6</td>\n",
              "      <td>50</td>\n",
              "      <td>entropy</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6565</td>\n",
              "      <td>0.8379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>gini</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6542</td>\n",
              "      <td>0.7484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>entropy</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6291</td>\n",
              "      <td>0.8273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>gini</td>\n",
              "      <td>None</td>\n",
              "      <td>0.6192</td>\n",
              "      <td>0.7106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>gini</td>\n",
              "      <td>balanced</td>\n",
              "      <td>0.6172</td>\n",
              "      <td>0.8575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   param_max_depth  param_min_samples_split param_criterion  \\\n",
              "1                2                      250         entropy   \n",
              "14            None                      250         entropy   \n",
              "15               4                      250            gini   \n",
              "9             None                      250            gini   \n",
              "4                3                      100         entropy   \n",
              "18               6                       50         entropy   \n",
              "13               2                       10            gini   \n",
              "2                3                       10         entropy   \n",
              "6                3                      100            gini   \n",
              "19               5                       50            gini   \n",
              "\n",
              "   param_class_weight  mean_test_roc_auc  mean_train_roc_auc  \n",
              "1            balanced             0.6840              0.7055  \n",
              "14           balanced             0.6840              0.7055  \n",
              "15           balanced             0.6840              0.7055  \n",
              "9            balanced             0.6840              0.7055  \n",
              "4            balanced             0.6676              0.7518  \n",
              "18           balanced             0.6565              0.8379  \n",
              "13           balanced             0.6542              0.7484  \n",
              "2            balanced             0.6291              0.8273  \n",
              "6                None             0.6192              0.7106  \n",
              "19           balanced             0.6172              0.8575  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantiad de combinaciones:  20\n",
            " \n",
            "El mejor AUROC promedio en validación obtenido fue de: 0.684\n",
            " \n",
            "Los mejores hiperparámetros obtenidos\n",
            " \n",
            "Profundidad del árbol  : 2\n",
            "Mínimos samples split  : 250\n",
            "Criterio               : entropy\n",
            "Class weight           : balanced\n"
          ]
        }
      ],
      "source": [
        "# primero vemos que hieprparametros vamos a elejir para armar los arboles\n",
        "\n",
        "param_distributions = {\n",
        "    \"max_depth\": [2, 3, 4, 5, 6, None],                 # profundidad máxima\n",
        "    \"class_weight\": [None, \"balanced\"],                 # para desbalanceo\n",
        "    \"criterion\": [\"gini\", \"entropy\"],                   # función de impureza\n",
        "    \"min_samples_split\": [10, 50, 100, 200, 250]        # mínimo para dividir\n",
        "}\n",
        "\n",
        "#  creamos el arbolito\n",
        "arbol = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# como metrica vamos a usar AUCROC\n",
        "scoring = {\n",
        "    \"roc_auc\": make_scorer(roc_auc_score),\n",
        "    \"auprc\": make_scorer(average_precision_score),\n",
        "    \"accuracy\": \"accuracy\" # Puedes usar el string para métricas comunes\n",
        "}\n",
        "\n",
        "# Ahora utilizamos la funcion RandomizedSearchCV\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=arbol,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=20,\n",
        "    scoring=scoring,\n",
        "    refit=\"roc_auc\",\n",
        "    cv=5,\n",
        "    # Habilita la creación de las columnas 'mean_train_...'\n",
        "    return_train_score=True,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "\n",
        "search.fit(x_desarrollo, y_desarrollo)\n",
        "\n",
        "\n",
        "# printeamos los resultados en una tabla en orden de los que dieron mejor AUCROC\n",
        "\n",
        "cvres = pd.DataFrame(search.cv_results_).sort_values(\"mean_test_roc_auc\", ascending=False)\n",
        "cols = [\n",
        "    \"param_max_depth\",\n",
        "    \"param_min_samples_split\",\n",
        "    \"param_criterion\",\n",
        "    \"param_class_weight\",\n",
        "    \"mean_test_roc_auc\",\n",
        "    \"mean_train_roc_auc\",\n",
        "]\n",
        "display(cvres[cols].head(10).round(4))\n",
        "\n",
        "print(\"Cantiad de combinaciones: \", 20 )\n",
        "print(\" \")\n",
        "print(\"El mejor AUROC promedio en validación obtenido fue de:\", search.best_score_.round(4))\n",
        "print(\" \")\n",
        "# Mejor combinación de hiperparámetros\n",
        "print(\"Los mejores hiperparámetros obtenidos\")\n",
        "print(\" \")\n",
        "print(\"Profundidad del árbol  :\", search.best_params_['max_depth'])\n",
        "print(\"Mínimos samples split  :\", search.best_params_['min_samples_split'])\n",
        "print(\"Criterio               :\", search.best_params_['criterion'])\n",
        "print(\"Class weight           :\", search.best_params_['class_weight'])\n",
        "\n",
        "\n",
        "df_tabla = cvres[cols].round(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5mYizrzb7To"
      },
      "source": [
        "# KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "aMfAW09vb9aX",
        "outputId": "70149a75-5f33-48dd-a659-288ee36cdc66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top 10 de los mejores resultados de KNN :\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>K (Vecinos)</th>\n",
              "      <th>Weights</th>\n",
              "      <th>Métrica de Distancia</th>\n",
              "      <th>AUROC val promedio</th>\n",
              "      <th>AUROC train promedio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>distance</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8759</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>uniform</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8603</td>\n",
              "      <td>0.8843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>distance</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8589</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8477</td>\n",
              "      <td>0.9034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>distance</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8473</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8319</td>\n",
              "      <td>0.8533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>uniform</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8243</td>\n",
              "      <td>0.8481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>distance</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8185</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>distance</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.8159</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>distance</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8132</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de combinaciones: 30\n",
            " \n",
            "Mejores hiperparámetros: {'weights': 'distance', 'n_neighbors': 58, 'metric': 'manhattan'}\n",
            " \n",
            "Mejor AUROC promedio en validación: 0.8759\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_distributions_knn = {\n",
        "    \"n_neighbors\": list(range(1,300)),\n",
        "    \"weights\": [\"uniform\", \"distance\"],\n",
        "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
        "}\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Solo AUROC\n",
        "scoring_knn = \"roc_auc\"\n",
        "\n",
        "search_knn = RandomizedSearchCV(\n",
        "    estimator=knn,\n",
        "    param_distributions=param_distributions_knn,\n",
        "    n_iter= 30 ,\n",
        "    scoring=scoring_knn,\n",
        "    refit=True,\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "# BUSCAMOS\n",
        "search_knn.fit(x_desarrollo, y_desarrollo)\n",
        "\n",
        "\n",
        "# tabla de resultados ordenada\n",
        "cvres_knn = pd.DataFrame(search_knn.cv_results_).sort_values(\n",
        "    \"mean_test_score\", ascending=False\n",
        ")\n",
        "\n",
        "cols_knn = [\n",
        "    \"param_n_neighbors\",\n",
        "    \"param_weights\",\n",
        "    \"param_metric\",\n",
        "    \"mean_test_score\",\n",
        "    \"mean_train_score\",\n",
        "]\n",
        "\n",
        "mapeo_nombres_knn = {\n",
        "    \"param_n_neighbors\": \"K (Vecinos)\",\n",
        "    \"param_weights\": \"Weights\",\n",
        "    \"param_metric\": \"Métrica de Distancia\",\n",
        "    \"mean_test_score\": \"AUROC val promedio\",\n",
        "    \"mean_train_score\": \"AUROC train promedio\",\n",
        "}\n",
        "\n",
        "print(\"\\n Top 10 de los mejores resultados de KNN :\")\n",
        "\n",
        "\n",
        "display(HTML(\n",
        "    cvres_knn[cols_knn]\n",
        "    .head(10)\n",
        "    .round(4)\n",
        "    .rename(columns=mapeo_nombres_knn)\n",
        "    .to_html(index=False, justify='center')\n",
        "))\n",
        "\n",
        "\n",
        "# printeamos los resultados\n",
        "print(\"Cantidad de combinaciones:\",30)\n",
        "print(\" \")\n",
        "print(\"Mejores hiperparámetros:\", search_knn.best_params_)\n",
        "print(\" \")\n",
        "print(\"Mejor AUROC promedio en validación:\", search_knn.best_score_.round(4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNi2QmXml4w3"
      },
      "source": [
        "Mirando cuanto nos dan los valores en el conjunto de entrenamiento, creemos que el modelo esta haciendo overfitting..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dO_oh4bmBSA"
      },
      "source": [
        "Veamos de los que son buenos, cuales sobreajustan menos. Para esto se nos ocurrió observar no solo el promedio de la metrica en el set de validacion, sino tambien observar la diferencia entre dicho valor y el promedio de la metrica en el set de train (s esto le llamamos \"gap\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "ZGQnb-H5iJDU",
        "outputId": "bca7d1f2-ce8c-4096-8c57-237ad73f0010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 con menor gap entre train y validacion:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>K (Vecinos)</th>\n",
              "      <th>Weights</th>\n",
              "      <th>Métrica de Distancia</th>\n",
              "      <th>AUROC val promedio</th>\n",
              "      <th>AUROC train promedio</th>\n",
              "      <th>Gap |Train - Val|</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.7346</td>\n",
              "      <td>0.7425</td>\n",
              "      <td>0.0079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>0.0083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.8049</td>\n",
              "      <td>0.0087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.7271</td>\n",
              "      <td>0.7380</td>\n",
              "      <td>0.0109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.7227</td>\n",
              "      <td>0.7346</td>\n",
              "      <td>0.0119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.7216</td>\n",
              "      <td>0.7373</td>\n",
              "      <td>0.0158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8072</td>\n",
              "      <td>0.8231</td>\n",
              "      <td>0.0159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.8010</td>\n",
              "      <td>0.8204</td>\n",
              "      <td>0.0195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8319</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.0215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>uniform</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8243</td>\n",
              "      <td>0.8481</td>\n",
              "      <td>0.0238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "cvres_overfit = cvres_knn.copy()\n",
        "cvres_overfit = cvres_overfit[cvres_overfit[\"mean_train_score\"] > cvres_overfit[\"mean_test_score\"]]\n",
        "cvres_overfit[\"generalization_gap\"] = (cvres_overfit[\"mean_train_score\"] - cvres_overfit[\"mean_test_score\"]).abs()\n",
        "\n",
        "# ordenamos por menor gap y, a igualdad de gap, mejor AUROC de validación\n",
        "cvres_overfit = cvres_overfit.sort_values(\n",
        "    by=[\"generalization_gap\",\"mean_test_score\"],\n",
        "    ascending=[True,False]\n",
        ")\n",
        "\n",
        "cols_overfit = [\n",
        "    \"param_n_neighbors\",\n",
        "    \"param_weights\",\n",
        "    \"param_metric\",\n",
        "    \"mean_test_score\",\n",
        "    \"mean_train_score\",\n",
        "    \"generalization_gap\",\n",
        "]\n",
        "\n",
        "mapeo_nombres_knn[\"generalization_gap\"] = \"Gap |Train - Val|\"\n",
        "\n",
        "print(\"\\nTop 10 con menor gap entre train y validacion:\")\n",
        "display(HTML(\n",
        "    cvres_overfit[cols_overfit]\n",
        "    .head(10)\n",
        "    .round(4)\n",
        "    .rename(columns=mapeo_nombres_knn)\n",
        "    .to_html(index=False, justify='center')\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOe1T1Pym7-Q"
      },
      "source": [
        "Como hay muchos casos en los que el aucroc en validacion nos da bastante alto , pero en el train nos da practicamente 1 ... nuestro modelo esta aprendiendose los datos de memoria y overfitea . Asi que decisimos tomar como \" el mejor\", el que tenga buen metrica AUCROC en validacion pero que tambien tenga poca diferencia entre lo que dio en train y val."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "ukJsJaUmkNP9",
        "outputId": "b218f17d-fb10-46f1-da30-3f212ed243ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 balanceados (AUROC alto + poco gap):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>K (Vecinos)</th>\n",
              "      <th>Weights</th>\n",
              "      <th>Métrica de Distancia</th>\n",
              "      <th>AUROC val promedio</th>\n",
              "      <th>AUROC train promedio</th>\n",
              "      <th>Gap |Train - Val|</th>\n",
              "      <th>Score combinado (AUROC↑, Gap↓)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63</td>\n",
              "      <td>uniform</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8603</td>\n",
              "      <td>0.8843</td>\n",
              "      <td>0.0240</td>\n",
              "      <td>0.9104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58</td>\n",
              "      <td>distance</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8759</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.8469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8477</td>\n",
              "      <td>0.9034</td>\n",
              "      <td>0.0557</td>\n",
              "      <td>0.8132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>62</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8319</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.0215</td>\n",
              "      <td>0.7891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>96</td>\n",
              "      <td>uniform</td>\n",
              "      <td>manhattan</td>\n",
              "      <td>0.8243</td>\n",
              "      <td>0.8481</td>\n",
              "      <td>0.0238</td>\n",
              "      <td>0.7527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>35</td>\n",
              "      <td>distance</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8589</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.1411</td>\n",
              "      <td>0.7498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87</td>\n",
              "      <td>uniform</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8072</td>\n",
              "      <td>0.8231</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.6883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>62</td>\n",
              "      <td>distance</td>\n",
              "      <td>minkowski</td>\n",
              "      <td>0.8473</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.1527</td>\n",
              "      <td>0.6840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>79</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.8082</td>\n",
              "      <td>0.8328</td>\n",
              "      <td>0.0246</td>\n",
              "      <td>0.6813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>92</td>\n",
              "      <td>uniform</td>\n",
              "      <td>euclidean</td>\n",
              "      <td>0.8010</td>\n",
              "      <td>0.8204</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.6562</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    K (Vecinos)   Weights Métrica de Distancia  AUROC val promedio  \\\n",
              "19           63   uniform            manhattan              0.8603   \n",
              "3            58  distance            manhattan              0.8759   \n",
              "12           22   uniform            minkowski              0.8477   \n",
              "25           62   uniform            minkowski              0.8319   \n",
              "10           96   uniform            manhattan              0.8243   \n",
              "9            35  distance            minkowski              0.8589   \n",
              "0            87   uniform            minkowski              0.8072   \n",
              "23           62  distance            minkowski              0.8473   \n",
              "15           79   uniform            euclidean              0.8082   \n",
              "5            92   uniform            euclidean              0.8010   \n",
              "\n",
              "    AUROC train promedio  Gap |Train - Val|  Score combinado (AUROC↑, Gap↓)  \n",
              "19                0.8843             0.0240                          0.9104  \n",
              "3                 1.0000             0.1241                          0.8469  \n",
              "12                0.9034             0.0557                          0.8132  \n",
              "25                0.8533             0.0215                          0.7891  \n",
              "10                0.8481             0.0238                          0.7527  \n",
              "9                 1.0000             0.1411                          0.7498  \n",
              "0                 0.8231             0.0159                          0.6883  \n",
              "23                1.0000             0.1527                          0.6840  \n",
              "15                0.8328             0.0246                          0.6813  \n",
              "5                 0.8204             0.0195                          0.6562  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# primero filtramos solo los casos donde  train > valid\n",
        "\n",
        "cvres_overfit = cvres_knn.copy()\n",
        "cvres_overfit = cvres_overfit[cvres_overfit[\"mean_train_score\"] > cvres_overfit[\"mean_test_score\"]].copy()\n",
        "\n",
        "# calcular gap\n",
        "cvres_overfit[\"generalization_gap\"] = (\n",
        "    cvres_overfit[\"mean_train_score\"] - cvres_overfit[\"mean_test_score\"]\n",
        ").abs()\n",
        "\n",
        "# hacemos una clase de score combinado\n",
        "# normalizamos AUROC y gap a [0,1]\n",
        "def minmax(s):\n",
        "    return (s - s.min()) / (s.max() - s.min() + 1e-12)\n",
        "\n",
        "auc_n = minmax(cvres_overfit[\"mean_test_score\"])\n",
        "gap_n = minmax(cvres_overfit[\"generalization_gap\"])\n",
        "\n",
        "alpha = 0.7\n",
        "cvres_overfit[\"score_mix\"] = alpha * auc_n + (1 - alpha) * (1 - gap_n)\n",
        "\n",
        "# ordenar por el score combinado\n",
        "cvres_ranked = cvres_overfit.sort_values(\"score_mix\", ascending=False)\n",
        "\n",
        "cols_rank = [\n",
        "    \"param_n_neighbors\",\n",
        "    \"param_weights\",\n",
        "    \"param_metric\",\n",
        "    \"mean_test_score\",\n",
        "    \"mean_train_score\",\n",
        "    \"generalization_gap\",\n",
        "    \"score_mix\",\n",
        "]\n",
        "\n",
        "mapeo_nombres_knn.update({\n",
        "    \"generalization_gap\": \"Gap |Train - Val|\",\n",
        "    \"score_mix\": \"Score combinado (AUROC↑, Gap↓)\",\n",
        "})\n",
        "\n",
        "print(\"\\nTop 10 balanceados (AUROC alto + poco gap):\")\n",
        "display(\n",
        "    cvres_ranked[cols_rank]\n",
        "    .head(10)\n",
        "    .round(4)\n",
        "    .rename(columns=mapeo_nombres_knn)\n",
        ")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.scatter(\n",
        "    cvres_overfit[\"generalization_gap\"],\n",
        "    cvres_overfit[\"mean_test_score\"],\n",
        "    alpha=0.5,\n",
        "    label=\"Modelos\"\n",
        ")\n",
        "\n",
        "top10 = cvres_ranked.head(10)\n",
        "plt.scatter(\n",
        "    top10[\"generalization_gap\"],\n",
        "    top10[\"mean_test_score\"],\n",
        "    color=\"red\",\n",
        "    s=60,\n",
        "    label=\"Top 10 balanceados\"\n",
        ")\n",
        "\n",
        "for _, r in top10.iterrows():\n",
        "    plt.annotate(f'K={r[\"param_n_neighbors\"]}',\n",
        "                 (r[\"generalization_gap\"], r[\"mean_test_score\"]),\n",
        "                 fontsize=8, xytext=(3,3), textcoords=\"offset points\")\n",
        "\n",
        "plt.xlabel(\"Gap |Train - Val| (AUROC)\")\n",
        "plt.ylabel(\"AUROC Validación (media CV)\")\n",
        "plt.title(\"KNN: equilibrio entre AUROC validación y gap\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7a9043b"
      },
      "source": [
        "# Support Vector Machines (SVM)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "26aad4f3",
        "outputId": "3b06e408-e434-436f-a049-062643455ccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top 10 de resultados con SVM:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>C</th>\n",
              "      <th>Kernel</th>\n",
              "      <th>Peso de Clase</th>\n",
              "      <th>Gamma</th>\n",
              "      <th>AUROC Prueba Promedio</th>\n",
              "      <th>AUROC train Promedio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>rbf</td>\n",
              "      <td>None</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>rbf</td>\n",
              "      <td>balanced</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>rbf</td>\n",
              "      <td>None</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>linear</td>\n",
              "      <td>balanced</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>linear</td>\n",
              "      <td>balanced</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>linear</td>\n",
              "      <td>None</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>linear</td>\n",
              "      <td>balanced</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>linear</td>\n",
              "      <td>None</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>linear</td>\n",
              "      <td>None</td>\n",
              "      <td>auto</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>linear</td>\n",
              "      <td>None</td>\n",
              "      <td>scale</td>\n",
              "      <td>0.7164</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cantidad de combinaciones: 40\n",
            "\n",
            "Mejores hiperparámetros para SVM: {'kernel': 'rbf', 'gamma': 'scale', 'class_weight': 'balanced', 'C': 45}\n",
            "\n",
            "Mejor AUROC promedio en validación para SVM: 0.8091\n"
          ]
        }
      ],
      "source": [
        "# primero definimos los parametros q vamos a usar\n",
        "param_distributions_svm = {\n",
        "    \"C\":  list(range(1,300)),  # costo de cuantos dejo q se escapen de mi clasificador ( aprox )\n",
        "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],  # nucleo\n",
        "    \"gamma\": [\"scale\", \"auto\"],\n",
        "    \"class_weight\": [None, \"balanced\"],\n",
        "}\n",
        "\n",
        "svm = SVC(random_state=0, probability=True)\n",
        "\n",
        "scoring_svm = {\n",
        "    \"roc_auc\": make_scorer(roc_auc_score),  # solo vamos a usar esta\n",
        "}\n",
        "\n",
        "search_svm = RandomizedSearchCV(\n",
        "    estimator=svm,\n",
        "    param_distributions=param_distributions_svm,\n",
        "    n_iter= 40,\n",
        "    scoring=scoring_svm,\n",
        "    refit=\"roc_auc\",\n",
        "    cv=5,\n",
        "    return_train_score=True,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "search_svm.fit(x_desarrollo, y_desarrollo)\n",
        "\n",
        "cvres_svm = pd.DataFrame(search_svm.cv_results_).sort_values(\"mean_test_roc_auc\", ascending=False)\n",
        "\n",
        "cols_svm = [\n",
        "    \"param_C\",\n",
        "    \"param_kernel\",\n",
        "    \"param_class_weight\",\n",
        "    \"param_gamma\",\n",
        "    \"mean_test_roc_auc\",\n",
        "    \"mean_train_roc_auc\",\n",
        "]\n",
        "\n",
        "print(\"\\n Top 10 de resultados con SVM:\")\n",
        "mapeo_nombres_svm = {\n",
        "    \"param_C\": \"C \",\n",
        "    \"param_kernel\": \"Kernel\",\n",
        "    \"param_gamma\": \"Gamma\",\n",
        "    \"param_class_weight\": \"Peso de Clase\",\n",
        "    \"mean_test_roc_auc\": \"AUROC Prueba Promedio\",\n",
        "    \"mean_train_roc_auc\": \"AUROC train Promedio\",\n",
        "}\n",
        "\n",
        "display(HTML(\n",
        "    cvres_svm[cols_svm]\n",
        "    .head(10)\n",
        "    .round(4)\n",
        "    .rename(columns=mapeo_nombres_svm)\n",
        "     .to_html(index=False, justify='center')\n",
        "))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Cantidad de combinaciones: 40\")\n",
        "print(\"\")\n",
        "print(\"Mejores hiperparámetros para SVM:\", search_svm.best_params_)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Mejor AUROC promedio en validación para SVM:\", search_svm.best_score_.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm6f2_2kqiZ1"
      },
      "source": [
        "> *Compare los resultados obtenidos en el ejercicio anterior con los siguientes modelos con sus hiperparámetros default. LDA (Linear discriminant analysis) Naïve Bayes*.\n",
        "\n",
        "> *¿Qué resultados obtuvo? ¿Qué hiperparámetros podrían ser relevantes explorar en estos modelos? ¿Por qué?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6vYsE47qgLi"
      },
      "source": [
        "# LDA y Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "9SfkylC0rLUW",
        "outputId": "d7dbac0b-7e3c-48a1-b0a0-0de36c160763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados comparativos LDA vs Naïve Bayes (k = 5):\n",
            " \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Modelo</th>\n",
              "      <th>AUROC train promedio</th>\n",
              "      <th>AUROC valid promedio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>LDA</td>\n",
              "      <td>0.998497</td>\n",
              "      <td>0.747897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Naïve Bayes</td>\n",
              "      <td>0.980553</td>\n",
              "      <td>0.825739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Ahora hacemos LDA Y Naive Bayes :\n",
        "\n",
        "# HACEMOS CROSS VALIDATION CON 5 FOLDS PARA LDA\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "cvres_lda = cross_validate(\n",
        "    lda,\n",
        "    x_desarrollo,\n",
        "    y_desarrollo,\n",
        "    cv=cv,\n",
        "    scoring=\"roc_auc\",\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# HACEMOS CROSS VALIDATION CON 5 FOLD PARA NAIVE BAYES\n",
        "\n",
        "nb = GaussianNB()\n",
        "cvres_nb = cross_validate(\n",
        "    nb,\n",
        "    x_desarrollo,\n",
        "    y_desarrollo,\n",
        "    cv=cv,\n",
        "    scoring=\"roc_auc\",\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Hacemos la table comparativa entre ambos modelos\n",
        "\n",
        "resultados = pd.DataFrame({\n",
        "    \"Modelo\": [\"LDA\", \"Naïve Bayes\"],\n",
        "    \"AUROC train promedio\": [cvres_lda[\"train_score\"].mean(), cvres_nb[\"train_score\"].mean()],\n",
        "    \"AUROC valid promedio\": [cvres_lda[\"test_score\"].mean(), cvres_nb[\"test_score\"].mean()],\n",
        "\n",
        "})\n",
        "\n",
        "print(\"Resultados comparativos LDA vs Naïve Bayes (k = 5):\")\n",
        "print(\" \")\n",
        "\n",
        "display(HTML(resultados.to_html(index=False, justify='center')))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg-slpBJtuii"
      },
      "source": [
        "Como vimos en la teorica , aunque Naive Bayes haga muchas suposiciones y tenga mucho sesgo inductivo, en la prática anda muy bien... despues de hacer estas prubas, estamos de acuerdo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUf-GC2WuILc"
      },
      "source": [
        "Hiperparametros de LDA :\n",
        "\n",
        "* solver ( svd, lsqr, eigen)\n",
        "* shrinkage ( None, auto) Ayuda cuando el número de muestras es pequeño en comparación con el número de características.(a nosotras nos re sirve)\n",
        "* n_components ( El número de dimensiones que se desea conservar después de la reducción de dimensionalidad )\n",
        "\n",
        "Hiperparametros de NB :\n",
        "\n",
        "* var_smoothing\n",
        "* alpha\n",
        "\n",
        "\n",
        "CONCLUSIONES :\n",
        "\n",
        "Para LDA nos combiene usar como hiperparametro shrinkage, ya que ayuda a reducir el sobreajuste, sobre todo en datasets con muchos atributos y pocas muestras.\n",
        "\n",
        "\n",
        "En Naïve Bayes, la performance depende mucho de cómo se maneja la varianza, por lo que var_smoothing es un hiperparámetro super importante para obtener buenos resultados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6teOOmtDwRJZ"
      },
      "source": [
        "> *¿Cuál fue el mejor modelo y con qué configuración? Explicar por qué creería que dio mejor (recordando qué hace cada algoritmo y con qué tipo de datos están trabajando).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6txM7HGgwUY7",
        "outputId": "b50e9ab0-bc0a-4401-ee75-792e2d0c9d20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: center;\">\n",
              "      <th>Modelo</th>\n",
              "      <th>Configuración elegida</th>\n",
              "      <th>AUROC Validación (media)</th>\n",
              "      <th>AUROC train (media)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Árboles</td>\n",
              "      <td>prof arbol 4, min splits = 250, entropy, clases balanceadas</td>\n",
              "      <td>0.7045</td>\n",
              "      <td>0.7048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>KNN</td>\n",
              "      <td>6 vecinos, pesos uniformes, dist manhattan</td>\n",
              "      <td>0.8339</td>\n",
              "      <td>0.8522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>SVM</td>\n",
              "      <td>nucleo gauseano, C=256, pesos balanceados</td>\n",
              "      <td>0.7809</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>LDA</td>\n",
              "      <td>default</td>\n",
              "      <td>0.7156</td>\n",
              "      <td>0.9941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>NB</td>\n",
              "      <td>default</td>\n",
              "      <td>0.8174</td>\n",
              "      <td>0.9709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Datos de los mejores modelos\n",
        "modelos = [\n",
        "    {\n",
        "        \"Modelo\": \"Árboles \",\n",
        "        \"Configuración elegida\": \"prof arbol 4, min splits = 250, entropy, clases balanceadas\",\n",
        "        \"AUROC Validación (media)\": 0.7045,\n",
        "        \"AUROC train (media)\": 0.7048,\n",
        "    },\n",
        "    {\n",
        "        \"Modelo\": \"KNN\",\n",
        "        \"Configuración elegida\": \"6 vecinos, pesos uniformes, dist manhattan\",\n",
        "        \"AUROC Validación (media)\": 0.8339,\n",
        "        \"AUROC train (media)\": 0.8522,\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"Modelo\": \"SVM\",\n",
        "        \"Configuración elegida\": \"nucleo gauseano, C=256, pesos balanceados\",\n",
        "        \"AUROC Validación (media)\": 0.7809,\n",
        "        \"AUROC train (media)\": 1.0000,\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"Modelo\": \"LDA\",\n",
        "        \"Configuración elegida\": \"default\",\n",
        "        \"AUROC Validación (media)\": 0.7156,\n",
        "        \"AUROC train (media)\": 0.9941,\n",
        "\n",
        "    },\n",
        "    {\n",
        "        \"Modelo\": \"NB\",\n",
        "        \"Configuración elegida\": \"default\",\n",
        "        \"AUROC Validación (media)\": 0.8174,\n",
        "        \"AUROC train (media)\": 0.9709,\n",
        "\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convertimos a DataFrame\n",
        "df_modelos = pd.DataFrame(modelos)\n",
        "\n",
        "# Mostramos tabla bonita\n",
        "display(HTML(df_modelos.to_html(index=False, justify=\"center\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1061-cfSysg0"
      },
      "source": [
        "- Arbol : Regulariza bien, evita overfitting con min_samples_split grande.\n",
        "\n",
        "- KNN : Mejor equilibrio entre AUROC alto y bajo gap (0.0183). Captura bien la estructura local de los datos.\n",
        "\n",
        "- SVM: Buen AUROC, pero obvio sobreajuste (train=1).\n",
        "\n",
        "- LDA : Alto sobreajuste: en train casi que es 1, pero baja en validación.\n",
        "    \n",
        "- NB : nos sorprende que de tan bien considerando que tiene un monton de sesgo inductivo. Menos gap que SVM, pero peor que KNN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwqKn5RBzJR8"
      },
      "source": [
        "Para nosotras el mejor modelo es el de KNN con los hipermarametros de la tabla. No solo tiene el mejor AUROC de validacion, sino que ademas es el que tiene menor gap entre val y train. Esto hace parecer que el modelo no esta sobreajustando a los datos de entrenamiento, por lo que decidimos quedarnos con este modelo como el mejor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJY_OkLqtZI2"
      },
      "source": [
        "Modelo ganador EN ESTE CASO... y con nuestros criterios de principiantes : KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Ql7wzQ6QuFie",
        "outputId": "7428da8e-0e90-4eba-a722-fd8d7fb8531f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<img src=\"https://i.imgur.com/VVzDmjr.jpeg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "display(Image(url=url))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
